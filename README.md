### 项目说明

该脚本仅用于辅助漏洞大模型项目的手工审查任务，无法保证所有输出完全满足要求。

使用之前请先大致看一下代码，毕竟不保证完全没问题，如果你觉得有问题可以自行修改。

#### 文件结构

`DeepSeek` 文件夹内包含 `API_process.py` 、`config.json` 以及 `update_ds_result.py` 三个文件，第一个为程序启动脚本，`config.json` 为配置文件，另一个为补丁脚本（后续会介绍用处）。

#### 配置文件说明

```bash
# config.json文件结构
{
    "INPUT_FILE": "your csv file path",
    "UPDATE_FILE": "the file you just want to update",
    "DEEPSEEK_API_KEY": "your_deepseek_api_key",
    "BAILIAN_API_KEY": "your_bailian_api_key",
    "SILICONFLOW_API_KEY": "your_siliconflow_api_key",
    "MAX_WORKERS": 24
}
```

- `INPUT_FILE`：你需要处理的 csv 文件路径
- `UPDATE_FILE`：补丁程序的输入，仅当你运行过旧版本程序时需要设置
- `API-KEY`，程序默认使用官网提供的 API 服务，因此想要开箱即用该字段必须配置
- `MAX_WORKERS`：程序并发数，用于提高处理速度。由于 `DeepSeek` 不限制用户并发度，所以该字段理论上可以随便设，不过不建议设得太大（防止请求堵塞）。实测并发度为 20 的情况下处理 200 条数据大概需要 1 小时，你可以根据自身需要适当进行调整。
- `BAILIAN_API_KEY`：百炼的 API，新版本代码会调用 百炼的 `V3`  提取 CWE 编号，因此需要设置下百炼的 `API-KEY`。百炼新用户会送 `100w` 个 token，所以这里 `V3` 直接薅免费的额度就行（当然你也可以直接把 `DS` 的 `API-KEY` 换成百炼的，但是 `DS` 凌晨有折扣，所以还是建议 `R1` 使用 `DS` 官网的 `API`，`V3` 薅羊毛）。
- `SILICONFLOW_API_KEY`：硅基流动的 API，由于之前硅基流动做活动（拉人+学生认证）送了不少免费额度，所以如果你有足够的免费额度也可以选择使用这个 API，不过可能需要自己修改下调用代码。
- 除此之外火山引擎之前也做活动送了不少免费额度，这里没列出，但是你可以自己修改加进去。

#### 程序运行

```bash
# 该脚本的环境依赖很少，按照编辑器报错简单配一下就行
python API_process.py
```

> 为了防止连接中断，强烈建议把程序挂后台运行

**之前的旧版本代码在提取 CWE 编号和生成正确输出时不够鲁棒，因此如果你运行过旧版本代码但是不想再从头开始运行一遍，请直接运行下面的补丁程序（文件路径在配置文件的 UPDATE_FILE 字段指定）：**

```bash
# 调用百炼V3重新提取一遍ds_result，同时验证correct_output的正确性
python update_ds_result.py
```

该补丁程序会更新你之前结果文件中的 `ds_output` 字段（提取出的 CWE 编号），同时会检查 `correct_output` 字段是否跟真实标签吻合。修改后的文件会存为带 `_updated` 后缀的文件，而不吻合的记录则会被记录到后缀为 `_correct_output_failed.csv` 的文件中用于人工审查。

#### 输出格式说明

程序默认输出文件名为 `[input_file]_result.csv`，输出文件在原始文件基础上增加了六个新的字段，各字段说明如下：

- `ds_think`：模型的完整思维链内容
- `ds_output`：模型的漏洞检测结果
- `ds_result`：模型检测出的漏洞编号（也可能检测出无漏洞）
- `is_correct`：模型检测出的漏洞编号是否覆盖所有的真实标签
- `correct_output`：我们期待的模型正确输出
- `ds_think_reduced`：精简过后的思维链
- `manual_review_needed`：指示生成的 `correct_output` 是否真的正确。如果字段为否，对应记录会被纳入后缀为 `_fail.csv` 的文件中，需要人工进行二次审查。

输出文件格式跟要求提交的格式稍微有点出入，因此需要手工修改一下。

这里的 `ds_think_reduced` 是精简过后的思维链，也就是老师要求的 `ds_think`，因此提交之前需要把 `ds_think` 字段的内容替换成 `ds_think_reduced` 字段，然后 `is_correct` 字段需要删掉，最终只留下 `替换后的 ds_think` + `ds_output` +`ds_result` + `correct_output` 四个字段。

**最后注意，毕竟是调的 API，程序也无法保证所有输出都是满足要求的。虽然尽可能做了优化，但是有时候还是会出现生成失败或者输出英文等情况，也可能出现比如 ds_output 和 ds_result 逻辑不一致或者 correct_output 与真实标签不一致的情况（比如真实标签为 CWE-250，但是模型输出判断漏洞为 CWE-233），虽然我们最新的代码中已经集成了重试和筛选的功能，但仍然无法完全避免这些问题。因此建议在执行 `API_process.py` 后根据输出文件中的 `manual_review_needed` 字段找出不一致的记录手工修正一下。**

---

### 注意事项（一定要看！！！）

- 该脚本中存在两处重试机制（精简思维链+正确答案生成），因此处理一条数据最多可能调用 7 次 R1 的 API，所以 token 消耗较大（V3 的调用 token 消耗较少且有免费额度，基本不会产生费用）。实测处理 470 条左右数据需要花费 70 元左右，我自己处理 200 条数据花了大概 30 元，因此强烈推荐 `00:30-8:30`使用，25 折还是很实惠的，基本上 20 以内应该可以跑完。
- 虽然程序兼容 excel 和 csv 处理，但是还是推荐使用 csv 格式作为输入。（excel 处理部分代码优化不足，因此使用 xlsx 文件的话可能会遇到如输出截断等未知错误）。
- 接上条，正式运行程序之前一定要检查一下你的 csv 文件格式是否正确，确保 csv 每一行对应的是一条完整的数据。有些行的数据转为 csv 格式后一行会变成两行，这种数据务必手工校正一下，否则程序可能会中途报错导致浪费大量 token（虽然程序已经做了健壮性检查，但是不保证一定能正确处理错误格式）。
- 最后再次强调，程序记得挂后台！防止连接中断浪费 token。